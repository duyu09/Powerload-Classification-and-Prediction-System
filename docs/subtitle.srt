1
00:00:00,566 --> 00:00:03,449
尊敬的评委老师，亲爱的同学们，大家好！

2
00:00:03,766 --> 00:00:04,883
我们的项目是

3
00:00:04,883 --> 00:00:06,683
基于深度学习算法的

4
00:00:06,683 --> 00:00:10,000
非入侵式电力负载分类与预测系统

5
00:00:10,666 --> 00:00:13,683
接下来，我将为大家详细讲解我们的项目

6
00:00:15,400 --> 00:00:17,000
我们小组合理分工

7
00:00:17,000 --> 00:00:18,766
共同完成了这个项目

8
00:00:19,000 --> 00:00:22,683
我将从以下几个方面对系统进行介绍

9
00:00:23,083 --> 00:00:25,733
首先，让我们来谈谈设计动机

10
00:00:26,483 --> 00:00:29,283
非入侵式电力负载分类与预测方法是指

11
00:00:29,283 --> 00:00:32,000
通过分析总用电数据

12
00:00:32,000 --> 00:00:33,683
无需监测具体设备

13
00:00:33,683 --> 00:00:36,883
即可推断并预测各个电器用电情况

14
00:00:37,400 --> 00:00:38,600
如右图所示

15
00:00:38,766 --> 00:00:40,883
系统不在每个电器的电源线上

16
00:00:40,883 --> 00:00:42,133
安装传感器

17
00:00:42,283 --> 00:00:45,283
而是通过分析入户总用电数据

18
00:00:45,400 --> 00:00:47,966
来推测各设备的使用情况

19
00:00:48,283 --> 00:00:50,933
以及预测未来短时间内的总功耗

20
00:00:52,800 --> 00:00:55,250
那么，为什么需要这样的技术呢？

21
00:00:55,366 --> 00:00:57,333
国家权威机构调查发现

22
00:00:57,450 --> 00:00:59,483
在我国乃至全世界

23
00:00:59,533 --> 00:01:01,600
因待机等非必要耗电

24
00:01:01,600 --> 00:01:04,566
造成电力资源浪费的现象日益严重

25
00:01:04,883 --> 00:01:07,600
另外，随着智能电网技术的兴起

26
00:01:07,766 --> 00:01:10,400
经济高效的非入侵式检测系统

27
00:01:10,566 --> 00:01:13,850
可满足广大用电与供电单位的需求

28
00:01:14,766 --> 00:01:16,483
并且，非入侵式系统

29
00:01:16,483 --> 00:01:19,200
不需要繁杂的传感器硬件支撑

30
00:01:19,483 --> 00:01:21,966
因而它成本低廉、可靠性高

31
00:01:21,966 --> 00:01:23,250
易被用户接受

32
00:01:23,933 --> 00:01:26,083
这项技术还有诸多优势

33
00:01:26,083 --> 00:01:27,250
由于时间原因

34
00:01:27,250 --> 00:01:28,766
不在此一一讲解

35
00:01:29,533 --> 00:01:32,133
另外我们所研发系统的算力

36
00:01:32,166 --> 00:01:35,333
来自国家超算山河计算平台

37
00:01:35,650 --> 00:01:38,600
响应了政府大力发展数字经济的号召

38
00:01:38,800 --> 00:01:41,133
是让算力走进千家万户

39
00:01:41,250 --> 00:01:43,883
赋能千行百业的生动体现

40
00:01:45,250 --> 00:01:48,883
总而言之，无论是普通家庭还是企业工厂

41
00:01:49,000 --> 00:01:51,533
都亟需一套智能算法和系统

42
00:01:51,566 --> 00:01:54,450
来监控电器的实时运行状态

43
00:01:54,600 --> 00:01:56,483
识别不必要的电力消耗

44
00:01:57,283 --> 00:01:59,083
这不仅有助于节约能源

45
00:01:59,083 --> 00:02:00,600
还能降低用电成本

46
00:02:01,600 --> 00:02:04,450
系统还应具备预测短期电能消耗的能力

47
00:02:04,783 --> 00:02:08,283
使企业能够更加科学地规划电力的使用

48
00:02:09,000 --> 00:02:12,166
特别是实行阶梯电价机制的情况

49
00:02:12,933 --> 00:02:14,050
为此，我们的系统

50
00:02:14,050 --> 00:02:16,733
主要包含分类与预测的功能

51
00:02:17,000 --> 00:02:18,450
其中分类功能

52
00:02:18,450 --> 00:02:19,883
可实时告知用户

53
00:02:19,933 --> 00:02:21,933
各电器设备的运作状态

54
00:02:22,250 --> 00:02:23,983
预测功能则能预估

55
00:02:24,050 --> 00:02:27,333
用户未来短时间内的电能消耗情况

56
00:02:28,000 --> 00:02:29,933
第二，算法设计

57
00:02:30,000 --> 00:02:32,800
我们的系统采用了级联模型架构

58
00:02:32,850 --> 00:02:35,050
分别包括分类分解模块

59
00:02:35,083 --> 00:02:36,600
和数值预测模块

60
00:02:36,883 --> 00:02:37,883
输入数据

61
00:02:37,933 --> 00:02:41,366
首先通过分类模块进行标签化处理

62
00:02:41,533 --> 00:02:42,333
随后

63
00:02:42,333 --> 00:02:46,566
数据及其标签被输入至数值预测模块

64
00:02:46,683 --> 00:02:49,133
以生成最终的功率预测值

65
00:02:50,533 --> 00:02:52,850
下面，我将分别进行介绍

66
00:02:53,050 --> 00:02:54,933
这是分类模型示意图

67
00:02:55,283 --> 00:02:58,200
首先，将输入的数据加窗处理

68
00:02:58,333 --> 00:03:00,650
再将功率数值进行分组

69
00:03:01,050 --> 00:03:03,683
接着，统计每个时间窗内

70
00:03:03,733 --> 00:03:05,600
落入各组的样本数量

71
00:03:05,600 --> 00:03:07,166
得到频数分布

72
00:03:08,000 --> 00:03:09,566
为了得到特征向量

73
00:03:09,566 --> 00:03:11,733
我们对每个时间窗的频数

74
00:03:11,800 --> 00:03:13,483
进行归一化处理

75
00:03:13,650 --> 00:03:15,000
即除以窗长

76
00:03:15,400 --> 00:03:18,333
最后，我们采用全连接神经网络

77
00:03:18,533 --> 00:03:21,366
输入由时间窗特征向量组成的矩阵

78
00:03:21,683 --> 00:03:25,083
从而输出对应电器类别的独热编码

79
00:03:26,533 --> 00:03:27,850
上述计算过程中

80
00:03:27,850 --> 00:03:29,966
我们采用了较短的窗长

81
00:03:30,050 --> 00:03:32,250
以及较多组的功率数值

82
00:03:32,683 --> 00:03:34,483
根据迪利克雷原理

83
00:03:34,533 --> 00:03:37,333
将会有很少的样本落入某个分组中

84
00:03:37,483 --> 00:03:40,450
因而特征矩阵将会非常稀疏

85
00:03:40,483 --> 00:03:42,650
无法直接输入神经网络

86
00:03:43,083 --> 00:03:46,333
需要经过主成分分析算法的压缩处理

87
00:03:46,850 --> 00:03:49,533
算法保留了96%的方差

88
00:03:49,733 --> 00:03:54,000
将660个维度的特征有效压缩为了17维

89
00:03:54,600 --> 00:03:57,533
使特征矩阵成为了密集矩阵

90
00:03:58,600 --> 00:03:59,800
选用模型时

91
00:03:59,800 --> 00:04:03,050
我们对比了全连接网络与GRU

92
00:04:03,083 --> 00:04:04,933
（门控循环单元）的性能

93
00:04:05,250 --> 00:04:07,133
经过超参数的调整

94
00:04:07,283 --> 00:04:12,166
两者分别可达到91%和90%的最高准确率

95
00:04:12,850 --> 00:04:14,566
但是上线测试说明

96
00:04:14,766 --> 00:04:17,450
GRU由于要关注其他时间窗

97
00:04:17,600 --> 00:04:20,366
其推理功耗明显大于全连接网络

98
00:04:20,450 --> 00:04:21,966
故我们选择后者

99
00:04:22,733 --> 00:04:25,283
我再来讲一下功率预测模型

100
00:04:25,283 --> 00:04:27,200
右图展示了同一电器

101
00:04:27,200 --> 00:04:29,483
不同时间跨度下的功率波形

102
00:04:29,966 --> 00:04:33,200
数据在宏观上极具规律性

103
00:04:34,050 --> 00:04:36,400
而微观上却毫无规律可言

104
00:04:36,933 --> 00:04:39,483
正是外部诸多的不确定因素

105
00:04:39,533 --> 00:04:42,366
为短时功率预测带来了挑战

106
00:04:43,600 --> 00:04:45,166
为了解决这一难题

107
00:04:45,166 --> 00:04:47,450
我们设计了如下模型结构

108
00:04:47,533 --> 00:04:48,883
在处理数据时

109
00:04:48,883 --> 00:04:51,166
首先对数据进行分帧处理

110
00:04:51,450 --> 00:04:54,200
然后在每个数据帧内进行分窗

111
00:04:54,566 --> 00:04:57,483
每个时间窗都会计算出一个特征向量

112
00:04:57,850 --> 00:04:59,766
多个时间窗的特征向量

113
00:04:59,800 --> 00:05:01,366
组成一个特征矩阵

114
00:05:01,800 --> 00:05:03,166
这些特征向量

115
00:05:03,200 --> 00:05:05,133
由波动大的暂态特征

116
00:05:05,200 --> 00:05:08,083
和不易变的稳态特征两部分组成

117
00:05:09,483 --> 00:05:12,133
暂态特征通过快速傅里叶变换

118
00:05:12,133 --> 00:05:15,250
得到各频率序数对应的振幅和相位

119
00:05:15,366 --> 00:05:17,333
而根据电学相关理论

120
00:05:17,450 --> 00:05:22,250
稳态特征由最大值、最小值、算术平均值

121
00:05:22,283 --> 00:05:23,566
能量有效值

122
00:05:23,566 --> 00:05:25,400
波峰系数等构成

123
00:05:26,483 --> 00:05:28,850
此外模型通过Embedding层

124
00:05:28,850 --> 00:05:32,816
将离散的电器种类映射为连续的嵌入向量

125
00:05:33,000 --> 00:05:35,650
作为稳态特征的重要组成部分

126
00:05:36,650 --> 00:05:38,933
受生成式语言模型的启发

127
00:05:39,000 --> 00:05:41,850
特征矩阵被视为“词嵌入矩阵"

128
00:05:43,050 --> 00:05:44,966
通过6层Transformer Block

129
00:05:44,966 --> 00:05:47,283
和后续的注意力平均化处理

130
00:05:47,283 --> 00:05:48,650
生成预测向量

131
00:05:49,733 --> 00:05:51,966
最后通过逆FFT

132
00:05:52,133 --> 00:05:53,333
将暂态特征中

133
00:05:53,333 --> 00:05:56,400
频域向量部分，转化为时间序列

134
00:05:56,483 --> 00:05:57,850
从而完成预测

135
00:05:58,933 --> 00:06:00,450
由于时间原因

136
00:06:00,600 --> 00:06:03,766
公式和具体计算过程不再过多阐述

137
00:06:03,933 --> 00:06:06,600
请老师们在文档和PPT中查阅参考

138
00:06:07,783 --> 00:06:11,533
如左图，实验结果最初并不尽如人意

139
00:06:11,650 --> 00:06:12,600
究其原因

140
00:06:12,600 --> 00:06:15,366
是Transformer不会关注一个时间步

141
00:06:15,366 --> 00:06:18,850
内部特征和特征各维度之间的关系

142
00:06:18,966 --> 00:06:20,766
而添加全连接网络

143
00:06:20,850 --> 00:06:23,000
则可以很好地解决这个问题

144
00:06:25,200 --> 00:06:27,450
这是我们经过改进后的模型

145
00:06:27,450 --> 00:06:29,333
在测试集上的效果

146
00:06:29,583 --> 00:06:33,533
可以看到，改进后的模型预测能力显著提高

147
00:06:36,283 --> 00:06:38,800
下面我将进行项目的演示

148
00:06:45,400 --> 00:06:47,450
第三部分，项目部署

149
00:06:48,133 --> 00:06:50,566
系统采用了“应用分布，算力集中”的

150
00:06:50,683 --> 00:06:52,199
云端协同架构

151
00:06:52,533 --> 00:06:54,333
数据库是系统的“枢纽”

152
00:06:54,483 --> 00:06:57,166
AI模型部署于算力网络

153
00:06:57,450 --> 00:06:59,400
电能表为边缘设备

154
00:06:59,533 --> 00:07:02,566
后端则分布于各小区或工厂

155
00:07:03,200 --> 00:07:04,400
MQ的设计

156
00:07:04,483 --> 00:07:07,250
削弱了来自分布式后端的请求洪峰

157
00:07:07,483 --> 00:07:09,650
减轻了GPU集群的压力

158
00:07:09,800 --> 00:07:11,766
提升了系统的整体性能

159
00:07:12,366 --> 00:07:15,400
这种设计耦合度低，且易于扩展

160
00:07:15,600 --> 00:07:18,483
符合现代化软件系统的设计模式

161
00:07:19,450 --> 00:07:20,483
项目开发时

162
00:07:20,483 --> 00:07:22,883
我们使用了英伟达 A100 GPU

163
00:07:22,933 --> 00:07:26,349
和英特尔第2代神经计算棒等硬件设备

164
00:07:26,800 --> 00:07:30,566
项目的运行环境则基于山河超算平台

165
00:07:30,600 --> 00:07:35,650
以及SQLite、微信小程序、PyTorch、C++工具链

166
00:07:35,683 --> 00:07:37,766
以及Rabbit MQ等软件

167
00:07:38,916 --> 00:07:42,766
现在展示的，是我们微信小程序客户端的界面

168
00:07:43,050 --> 00:07:45,650
我们主要使用了微信开发者工具

169
00:07:45,683 --> 00:07:47,083
进行前端开发

170
00:07:47,283 --> 00:07:52,449
波形绘制，使用了ECharts库中提供的折线图组件

171
00:07:52,850 --> 00:07:56,966
后端程序使用C++17标准构建的Web Server

172
00:07:57,200 --> 00:07:59,366
基于单Reactor多线程架构

173
00:08:00,050 --> 00:08:03,566
系统核心由日志记录、线程池管理

174
00:08:03,650 --> 00:08:06,333
IO多路复用、HTTP处理

175
00:08:06,366 --> 00:08:09,850
缓冲区管理和阻塞队列等模块组成

176
00:08:10,566 --> 00:08:14,283
HTTP请求报文通过分散读方式读入

177
00:08:14,566 --> 00:08:16,483
并利用有限状态机

178
00:08:16,483 --> 00:08:18,850
与正则表达式进行高效解析

179
00:08:20,533 --> 00:08:22,333
最后是项目总结

180
00:08:22,883 --> 00:08:25,166
白驹过隙，时光荏苒

181
00:08:25,333 --> 00:08:26,733
回眸数月时光

182
00:08:26,933 --> 00:08:29,949
在贾瑞祥老师和陈静老师的悉心指导下

183
00:08:30,166 --> 00:08:32,000
我们五人通力合作

184
00:08:32,050 --> 00:08:33,250
以赛促学

185
00:08:33,333 --> 00:08:34,366
收获颇丰

186
00:08:34,733 --> 00:08:37,366
终于研发出了这个规模不小的系统

187
00:08:37,850 --> 00:08:40,050
至此，我们的项目汇报完毕

188
00:08:40,283 --> 00:08:44,266
衷心感谢各位评委老师的倾听和指教

