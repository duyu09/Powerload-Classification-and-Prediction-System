1
00:00:00,766 --> 00:00:03,650
尊敬的评委老师，亲爱的同学们，大家好！

2
00:00:03,966 --> 00:00:05,083
我们的项目是

3
00:00:05,083 --> 00:00:06,883
基于深度学习算法的

4
00:00:06,883 --> 00:00:10,200
非入侵式电力负载分类与预测系统

5
00:00:10,866 --> 00:00:13,883
接下来，我将为大家详细讲解我们的项目

6
00:00:15,600 --> 00:00:17,200
我们小组合理分工

7
00:00:17,200 --> 00:00:18,966
共同完成了这个项目

8
00:00:19,200 --> 00:00:22,883
我将从以下几个方面对系统进行介绍

9
00:00:23,283 --> 00:00:25,933
首先，让我们来谈谈设计动机

10
00:00:26,683 --> 00:00:29,483
非入侵式电力负载分类与预测方法是指

11
00:00:29,483 --> 00:00:32,200
通过分析总用电数据

12
00:00:32,200 --> 00:00:33,883
无需监测具体设备

13
00:00:33,883 --> 00:00:37,083
即可推断并预测各个电器用电情况

14
00:00:37,600 --> 00:00:38,800
如右图所示

15
00:00:38,966 --> 00:00:41,083
系统不在每个电器的电源线上

16
00:00:41,083 --> 00:00:42,333
安装传感器

17
00:00:42,483 --> 00:00:45,483
而是通过分析入户总用电数据

18
00:00:45,600 --> 00:00:48,166
来推测各设备的使用情况

19
00:00:48,483 --> 00:00:51,133
以及预测未来短时间内的总功耗

20
00:00:53,000 --> 00:00:55,450
那么，为什么需要这样的技术呢？

21
00:00:55,566 --> 00:00:57,533
国家权威机构调查发现

22
00:00:57,650 --> 00:00:59,683
在我国乃至全世界

23
00:00:59,733 --> 00:01:01,800
因待机等非必要耗电

24
00:01:01,800 --> 00:01:04,766
造成电力资源浪费的现象日益严重

25
00:01:05,083 --> 00:01:07,800
另外，随着智能电网技术的兴起

26
00:01:07,966 --> 00:01:10,600
经济高效的非入侵式检测系统

27
00:01:10,766 --> 00:01:14,050
可满足广大用电与供电单位的需求

28
00:01:14,966 --> 00:01:16,683
并且，非入侵式系统

29
00:01:16,683 --> 00:01:19,400
不需要繁杂的传感器硬件支撑

30
00:01:19,683 --> 00:01:22,166
因而它成本低廉、可靠性高

31
00:01:22,166 --> 00:01:23,450
易被用户接受

32
00:01:24,133 --> 00:01:26,283
这项技术还有诸多优势

33
00:01:26,283 --> 00:01:27,450
由于时间原因

34
00:01:27,450 --> 00:01:28,966
不在此一一讲解

35
00:01:29,733 --> 00:01:32,333
另外我们所研发系统的算力

36
00:01:32,366 --> 00:01:35,533
来自国家超算山河计算平台

37
00:01:35,850 --> 00:01:38,800
响应了政府大力发展数字经济的号召

38
00:01:39,000 --> 00:01:41,333
是让算力走进千家万户

39
00:01:41,450 --> 00:01:44,083
赋能千行百业的生动体现

40
00:01:45,450 --> 00:01:49,083
总而言之，无论是普通家庭还是企业工厂

41
00:01:49,200 --> 00:01:51,733
都亟需一套智能算法和系统

42
00:01:51,766 --> 00:01:54,650
来监控电器的实时运行状态

43
00:01:54,800 --> 00:01:56,683
识别不必要的电力消耗

44
00:01:57,483 --> 00:01:59,283
这不仅有助于节约能源

45
00:01:59,283 --> 00:02:00,800
还能降低用电成本

46
00:02:01,800 --> 00:02:04,650
系统还应具备预测短期电能消耗的能力

47
00:02:04,983 --> 00:02:08,483
使企业能够更加科学地规划电力的使用

48
00:02:09,200 --> 00:02:12,366
特别是实行阶梯电价机制的情况

49
00:02:13,133 --> 00:02:14,250
为此，我们的系统

50
00:02:14,250 --> 00:02:16,933
主要包含分类与预测的功能

51
00:02:17,200 --> 00:02:18,650
其中分类功能

52
00:02:18,650 --> 00:02:20,083
可实时告知用户

53
00:02:20,133 --> 00:02:22,133
各电器设备的运作状态

54
00:02:22,450 --> 00:02:24,183
预测功能则能预估

55
00:02:24,250 --> 00:02:27,533
用户未来短时间内的电能消耗情况

56
00:02:28,200 --> 00:02:30,133
第二，算法设计

57
00:02:30,200 --> 00:02:33,000
我们的系统采用了级联模型架构

58
00:02:33,050 --> 00:02:35,250
分别包括分类分解模块

59
00:02:35,283 --> 00:02:36,800
和数值预测模块

60
00:02:37,083 --> 00:02:38,083
输入数据

61
00:02:38,133 --> 00:02:41,566
首先通过分类模块进行标签化处理

62
00:02:41,733 --> 00:02:42,533
随后

63
00:02:42,533 --> 00:02:46,766
数据及其标签被输入至数值预测模块

64
00:02:46,883 --> 00:02:49,333
以生成最终的功率预测值

65
00:02:50,733 --> 00:02:53,050
下面，我将分别进行介绍

66
00:02:53,250 --> 00:02:55,133
这是分类模型示意图

67
00:02:55,483 --> 00:02:58,400
首先，将输入的数据加窗处理

68
00:02:58,533 --> 00:03:00,850
再将功率数值进行分组

69
00:03:01,250 --> 00:03:03,883
接着，统计每个时间窗内

70
00:03:03,933 --> 00:03:05,800
落入各组的样本数量

71
00:03:05,800 --> 00:03:07,366
得到频数分布

72
00:03:08,200 --> 00:03:09,766
为了得到特征向量

73
00:03:09,766 --> 00:03:11,933
我们对每个时间窗的频数

74
00:03:12,000 --> 00:03:13,683
进行归一化处理

75
00:03:13,850 --> 00:03:15,200
即除以窗长

76
00:03:15,600 --> 00:03:18,533
最后，我们采用全连接神经网络

77
00:03:18,733 --> 00:03:21,566
输入由时间窗特征向量组成的矩阵

78
00:03:21,883 --> 00:03:25,283
从而输出对应电器类别的独热编码

79
00:03:26,733 --> 00:03:28,050
上述计算过程中

80
00:03:28,050 --> 00:03:30,166
我们采用了较短的窗长

81
00:03:30,250 --> 00:03:32,450
以及较多组的功率数值

82
00:03:32,883 --> 00:03:34,683
根据迪利克雷原理

83
00:03:34,733 --> 00:03:37,533
将会有很少的样本落入某个分组中

84
00:03:37,683 --> 00:03:40,650
因而特征矩阵将会非常稀疏

85
00:03:40,683 --> 00:03:42,850
无法直接输入神经网络

86
00:03:43,283 --> 00:03:46,533
需要经过主成分分析算法的压缩处理

87
00:03:47,050 --> 00:03:49,733
算法保留了96%的方差

88
00:03:49,933 --> 00:03:54,200
将660个维度的特征有效压缩为了17维

89
00:03:54,800 --> 00:03:57,733
使特征矩阵成为了密集矩阵

90
00:03:58,800 --> 00:04:00,000
选用模型时

91
00:04:00,000 --> 00:04:03,250
我们对比了全连接网络与GRU

92
00:04:03,283 --> 00:04:05,133
（门控循环单元）的性能

93
00:04:05,450 --> 00:04:07,333
经过超参数的调整

94
00:04:07,483 --> 00:04:12,366
两者分别可达到91%和90%的最高准确率

95
00:04:13,050 --> 00:04:14,766
但是上线测试说明

96
00:04:14,966 --> 00:04:17,650
GRU由于要关注其他时间窗

97
00:04:17,800 --> 00:04:20,566
其推理功耗明显大于全连接网络

98
00:04:20,650 --> 00:04:22,166
故我们选择后者

99
00:04:22,933 --> 00:04:25,483
我再来讲一下功率预测模型

100
00:04:25,483 --> 00:04:27,400
右图展示了同一电器

101
00:04:27,400 --> 00:04:29,683
不同时间跨度下的功率波形

102
00:04:30,166 --> 00:04:33,400
数据在宏观上极具规律性

103
00:04:34,250 --> 00:04:36,600
而微观上却毫无规律可言

104
00:04:37,133 --> 00:04:39,683
正是外部诸多的不确定因素

105
00:04:39,733 --> 00:04:42,566
为短时功率预测带来了挑战

106
00:04:43,800 --> 00:04:45,366
为了解决这一难题

107
00:04:45,366 --> 00:04:47,650
我们设计了如下模型结构

108
00:04:47,733 --> 00:04:49,083
在处理数据时

109
00:04:49,083 --> 00:04:51,366
首先对数据进行分帧处理

110
00:04:51,650 --> 00:04:54,400
然后在每个数据帧内进行分窗

111
00:04:54,766 --> 00:04:57,683
每个时间窗都会计算出一个特征向量

112
00:04:58,050 --> 00:04:59,966
多个时间窗的特征向量

113
00:05:00,000 --> 00:05:01,566
组成一个特征矩阵

114
00:05:02,000 --> 00:05:03,366
这些特征向量

115
00:05:03,400 --> 00:05:05,333
由波动大的暂态特征

116
00:05:05,400 --> 00:05:08,283
和不易变的稳态特征两部分组成

117
00:05:09,683 --> 00:05:12,333
暂态特征通过快速傅里叶变换

118
00:05:12,333 --> 00:05:15,450
得到各频率序数对应的振幅和相位

119
00:05:15,566 --> 00:05:17,533
而根据电学相关理论

120
00:05:17,650 --> 00:05:22,450
稳态特征由最大值、最小值、算术平均值

121
00:05:22,483 --> 00:05:23,766
能量有效值

122
00:05:23,766 --> 00:05:25,600
波峰系数等构成

123
00:05:26,683 --> 00:05:29,050
此外模型通过Embedding层

124
00:05:29,050 --> 00:05:33,016
将离散的电器种类映射为连续的嵌入向量

125
00:05:33,200 --> 00:05:35,850
作为稳态特征的重要组成部分

126
00:05:36,850 --> 00:05:39,133
受生成式语言模型的启发

127
00:05:39,200 --> 00:05:42,050
特征矩阵被视为“词嵌入矩阵"

128
00:05:43,250 --> 00:05:45,166
通过6层Transformer Block

129
00:05:45,166 --> 00:05:47,483
和后续的注意力平均化处理

130
00:05:47,483 --> 00:05:48,850
生成预测向量

131
00:05:49,933 --> 00:05:52,166
最后通过逆FFT

132
00:05:52,333 --> 00:05:53,533
将暂态特征中

133
00:05:53,533 --> 00:05:56,600
频域向量部分，转化为时间序列

134
00:05:56,683 --> 00:05:58,050
从而完成预测

135
00:05:59,133 --> 00:06:00,650
由于时间原因

136
00:06:00,800 --> 00:06:03,966
公式和具体计算过程不再过多阐述

137
00:06:04,133 --> 00:06:06,800
请老师们在文档和PPT中查阅参考

138
00:06:07,983 --> 00:06:11,733
如左图，实验结果最初并不尽如人意

139
00:06:11,850 --> 00:06:12,800
究其原因

140
00:06:12,800 --> 00:06:15,566
是Transformer不会关注一个时间步

141
00:06:15,566 --> 00:06:19,050
内部特征和特征各维度之间的关系

142
00:06:19,166 --> 00:06:20,966
而添加全连接网络

143
00:06:21,050 --> 00:06:23,200
则可以很好地解决这个问题

144
00:06:25,400 --> 00:06:27,650
这是我们经过改进后的模型

145
00:06:27,650 --> 00:06:29,533
在测试集上的效果

146
00:06:29,783 --> 00:06:33,733
可以看到，改进后的模型预测能力显著提高

147
00:06:36,483 --> 00:06:39,000
下面我将进行项目的演示

148
00:07:33,500 --> 00:07:35,550
第三部分，项目部署

149
00:07:35,866 --> 00:07:38,300
系统采用了“应用分布，算力集中”的

150
00:07:38,416 --> 00:07:39,933
云端协同架构

151
00:07:40,266 --> 00:07:42,066
数据库是系统的“枢纽”

152
00:07:42,216 --> 00:07:44,900
AI模型部署于算力网络

153
00:07:45,183 --> 00:07:47,133
电能表为边缘设备

154
00:07:47,266 --> 00:07:50,300
后端则分布于各小区或工厂

155
00:07:50,933 --> 00:07:52,133
MQ的设计

156
00:07:52,216 --> 00:07:54,983
削弱了来自分布式后端的请求洪峰

157
00:07:55,216 --> 00:07:57,383
减轻了GPU集群的压力

158
00:07:57,533 --> 00:07:59,500
提升了系统的整体性能

159
00:08:00,100 --> 00:08:03,133
这种设计耦合度低，且易于扩展

160
00:08:03,333 --> 00:08:06,216
符合现代化软件系统的设计模式

161
00:08:07,183 --> 00:08:08,216
项目开发时

162
00:08:08,216 --> 00:08:10,616
我们使用了英伟达 A100 GPU

163
00:08:10,666 --> 00:08:14,083
和英特尔第2代神经计算棒等硬件设备

164
00:08:14,533 --> 00:08:18,300
项目的运行环境则基于山河超算平台

165
00:08:18,333 --> 00:08:23,383
以及SQLite、微信小程序、PyTorch、C++工具链

166
00:08:23,416 --> 00:08:25,500
以及Rabbit MQ等软件

167
00:08:26,650 --> 00:08:30,500
现在展示的，是我们微信小程序客户端的界面

168
00:08:30,783 --> 00:08:33,383
我们主要使用了微信开发者工具

169
00:08:33,416 --> 00:08:34,816
进行前端开发

170
00:08:35,016 --> 00:08:40,183
波形绘制，使用了ECharts库中提供的折线图组件

171
00:08:40,583 --> 00:08:44,700
后端程序使用C++17标准构建的Web Server

172
00:08:44,933 --> 00:08:47,100
基于单Reactor多线程架构

173
00:08:47,783 --> 00:08:51,300
系统核心由日志记录、线程池管理

174
00:08:51,383 --> 00:08:54,066
IO多路复用、HTTP处理

175
00:08:54,100 --> 00:08:57,583
缓冲区管理和阻塞队列等模块组成

176
00:08:58,300 --> 00:09:02,016
HTTP请求报文通过分散读方式读入

177
00:09:02,300 --> 00:09:04,216
并利用有限状态机

178
00:09:04,216 --> 00:09:06,583
与正则表达式进行高效解析

179
00:09:08,266 --> 00:09:10,066
最后是项目总结

180
00:09:10,616 --> 00:09:12,900
白驹过隙，时光荏苒

181
00:09:13,066 --> 00:09:14,466
回眸数月时光

182
00:09:14,666 --> 00:09:17,683
在贾瑞祥老师和陈静老师的悉心指导下

183
00:09:17,900 --> 00:09:19,733
我们五人通力合作

184
00:09:19,783 --> 00:09:20,983
以赛促学

185
00:09:21,066 --> 00:09:22,100
收获颇丰

186
00:09:22,466 --> 00:09:25,100
终于研发出了这个规模不小的系统

187
00:09:25,583 --> 00:09:27,783
至此，我们的项目汇报完毕

188
00:09:28,016 --> 00:09:32,000
衷心感谢各位评委老师的倾听和指教

